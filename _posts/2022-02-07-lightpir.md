---
layout: post
title: LightPIR. Privacy-Preserving Route Discovery for Lightning (paper summary)
published: false
---

<!-- CHANGE PUBLISHED TO FALSE TO PUSH AS DRAFT -->
<!-- CHANGE DATE BEFORE PUBLICATION -->

In this post, I summarize the paper "LightPIR".
The paper outlines a new approach to route discovery in the LN.
The method combines private information retrieval with optimized hub labeling.


# Lightning routing problem

Multi-hop payments are the key advantage of Lightning.
Users may exchange payments even though their nodes don't share a direct channel.
Without multi-hop payments, the scaling prospects of Lightning would be moderate at best.

Routing is thus an integral part of Lightning.
Routing may be divided into two steps: route discovery (also known as path-finding) and forwarding a payment.
Let's focus on _route discovery_ first.

Consider Alice who wants to pay Bob.
Alice and Bob don't share a channel.
Alice must choose the entire route towards Bob to start a payment.
(In other words, Lightning is _source routed_.)

Do perform route discovery, Alice needs to store a snapshot of the entire network.
Here lies the key problem we'll be discussing in this post.
At the time of this writing, the LN contains XX nodes and CC channels.
This isn't a lot by modern hardware standards.
However, if we envision Lightning growing by many orders of magnitude, route discovery may become challenging.

One of the key pillars of Lightning (and Bitcoin) design philosophy is that the protocol must remain usable on devices with limited resources.
There are different types of resources one might consider:
- computing power;
- storage;
- communication speed and latency;
- energy consumption.

Ideally, we'd like Lightning to work even on an IoT device with a tiny battery and sporadic Internet connection.
Under such constraints, finding routes in a graph of millions of nodes and channels would be difficult.


# A naive trust-based solution

Most of the problems of this kind may be solved by introducing trust.
I know, I know, eliminating the need for trust is the main point of the whole Bitcoin ecosystem!
Still, let's discuss a naive trust-based solution first, and then try build on top of it.

Let's go the most natural way and allocate some _specialized_ nodes (let's call them _servers_) to do route discovery!
There are two ways to go about this.
First, a server may simply store the network snapshot and calculate a route from Alice to Bob when Alice asks for it.
Second, a server may _pre-calculate_ routes for _each_ pair of nodes, so that when Alice asks for a route to Bob, the server just needs to look up a row in its database.
The first approach puts less of a burden on a server, which uses the minimal amount of resources.
The second approach is more demanding for the server: it has to spend computational resources to pre-compute all routes and extra storage to store them.
However, the user experience is better as the user gets a requested route faster.
Of course, realistic implementations would combine the two approaches, pre-calculating _some_ routes while discovering others just-in-time.
We will refer to this family of protocols as **APSP**, which stands for "**all pairs shortest paths**".

APSP approaches present two key challenges: efficiency and privacy.

First, consider efficiency.
Even though we've outsourced route discovery to servers that are more powerful than clients, but with a very large graph even servers' capabilities may not be sufficient.
Efficiency is a complex metric: it may include the following:
- server-side computation;
- server-side storage;
- client-side computation;
- client-side storage;
- communication.

One variation of an APSP protocol, for example, could involve the server pre-computing and storing all possible paths.
That would mean high server-side computation and storage and low client-side computation and storage.
Another (extreme) variation could simply send the whole graph to the client and let if figure out the route by itself.
(It's stupid, but let's consider it for the sake of example.)
Such protocol would incur minimal costs on the server but substantial costs on the client (both in terms of storage and computation), as well as a high communication cost.

Second, consider privacy.
In all APSP protocols we've considered so far, the server knows what route a client is interested in.
In the Lightning context in particular, that means the server knows who is paying whom, which is not private at all.

Here are the key questions we ponder:
- Is it possible to implement server-client-based route discovery while preserving clients' privacy?
- Is is possible to come up with a protocol with a balanced resource requirements in terms of these five metrics?

Let's address them in turn.


# Private information retrieval (solving privacy)

Let's put the Lightning specifics aside for a moment and consider a generic client-server architecture.
The server stores a database which, for simplicity, is an array of boolean values.
The client wants to obtain the `i`-th value from the array.

In a simple (non-private) protocol, the client sends the index `i` to the server, and the server replies with `DB[i]`.
Obviously, the server now knows which element the client is interested in.

Is it possible for a client to obtain `DB[i]` _without the server knowing_ `i`?
Indeed, this sounds absurd.
Moreover, it has been proven that the only way to solve this challenge is to send the whole database to the client.
Case closed?
Not so fast.
When faced with an impossibility result, can't we _bend_ the rules a little bit?
Instead of the problem we know is unsolvable, we can consider another, related problem by making more security assumptions.

This is where **private information retrieval** (PIR) comes in.

There are two branches of PIR: computational (CPIR) and information-theoretical (IT_PIR).
CPIR allows for PIR with a single server but is slower and involves advanced cryptography (keyword: fully homomorphic encryption).
CPIR is outside the scope of this post.
IT-PIR, on the other hand, is fast, uses cheap cryptography, but only works with _multiple_ servers.
We'll focus on IT-PIR.

Consider _two_ servers holding copies of the same database.
The **additional security assumption** is that the servers don't collude.
Here is how a simple PIR protocol would work.

1. the client generates a random string `r` and another string `r'` that only differs from `r` in the `i`-th bit;
1. the client sends `r` to the first server;
1. the first server responds with a single bit `d` that is a XOR of elements at all indices `j` where `r[j]=1`;
1. the client sends `r'` to the second server;
1. the second server responds analogously with a single bit `d`;
1. the client locally computes `d XOR d' = D[i]`.

In other words, the client obtains two XOR's of nearly identical subsets of database elements.
The subsets only differ in that one includes `D[i]` and the other doesn't.
By XOR'ing them together, the client discovers `D[i]` locally in full privacy.

The simple PIR algorithm presented above is very ineffective.
Server-side computation cost and the communication cost are linear in the database size.
Note that even though each response is a single bit long, the _request_ `r` is as long as the database itself.
Advanced PIR protocols improve efficiency.
One idea, intuitively, is for the client to request only some random _subset_ of indices.
By choosing these subsets cleverly, we can mathematically guarantee that the result still equals `D[i]`.
For more details, see [this introductory lecture](https://www.youtube.com/watch?v=HFFPeYrz3ak).


# Hub labeling (solving efficiency)

Now let's discuss efficiency.
There are many well-established route discovery algorithms, such as the Dijkstra algorithm, but for very large graphs they may be inefficient.
Yet, I can select two points on the opposite coasts of a continent in any online map, and the routing engine will produce a thousands-kilometers-long route in a few seconds.
How is this possible?

Turns out, there is a lot of space for optimizations in route discovery.
Note that for practical applications we're not that interested in theoretical complexity.
Our prime concern is to make the algorithm fast on _real_ graphs.
To do that, we can exploit the properties of those graphs -- vaguely speaking, their centralized nature.

Consider maps as an example.
Road networks may have millions of intersections.
Yet, those intersections are far from being equally likely to occur on a route between two random points.
On the contrary: most if not all routes of non-trivial length follow this pattern:
1. drive to the nearest highway entrance;
1. drive along the highway;
1. exit the highway and drive to your destination.

Highways comprise a small minority of roads but play a disproportionately important role in long-distance travel.
That's the point of a highway network, after all.
With that in mind, route discovery algorithms have been heavily optimized.

A key optimization is called **hub labeling**.
Informally, a hub is a node that is part of _many_ _sufficiently long_ _shortest_ paths.
Each word in italics in the previous sentence should be and of course formally defined in the literature.
Remember an earlier APSP method, where the server pre-computes routes for each pair of nodes?
Let's modify APSP with the hub topology in mind.

The server now stores along with each node a list of hubs and the shortest route to each hub.
Finding a route from Alice to Bob goes like this:
1. find a hub that belong both to Alice's and to Bob's hub sets;
1. the route is: Alice - hub - Bob.

An attentive reader might spot an issue here.
What happens if there is no common hub between Alice and Bob?
Indeed, that would an issue!
To avoid this, the hub sets are chosen such that **intersect all shortest paths** of non-trivial length.
This problem is equivalent to the hitting set problem and the cover set problem, and is therefore NP-hard.
Multiple heuristics have been developed, and they do the job well enough for practical applications.
Hub sets computed by a heuristic allow for discovering a shortest route between any pair of nodes, but include more nodes than necessary.
As the final performance is _much_ better than the naive APSP approach, we can tolerate this inefficiency.


# LightPIR: putting this all together

At long last, let's discuss what the LightPIR paper proposes!

The authors suggest a combination of PIR and hub labeling (HL) for route discovery in payment channel networks (such as Lightning).
The proposed protocol has three types of roles: a content provider, servers, and clients.
It goes as follows:

1. the content provider creates a network snapshot and sends its copies to the servers;
1. each server performs hub labeling on the snapshot;
1. clients query multiple servers using a PIR protocol for routes they are interested in.

The key novelty of the paper is an improved HL algorithm tailored for the LN topology specifically.
In simple terms, the LN is _even more_ centralized than highway networks, therefore, its structure can be more effectively exploited.
In particular, the authors describe a new HL algorithm that goes like this:
1. select `K` nodes with the highest degree, put them in the hub set for all nodes (IS TI TRUE?)
1. exclude those hubs from the graph
1. find the "remaining" hubs based on the "truncated" graph.

This make a ton of sense if one considers the de-facto hub-and-spoke structure of Lightning.
Consider ACINQ -- the most connected node on the network ran by the company of the same name.
In prior algorithms, we would be repeatedly "discovering" that ACINQ node is a hub for Alice, and for Bob, and for Charlie (what a surprise!).
Instead, we simply add ACINQ to the hub set for all nodes.
The same applies to `K` highest connected nodes, which are then temporarily pruned from the graph.
Additional "node-specific" hubs are then discovered on a pruned graph, which further simplifies calculations.
How many top-connected nodes shall we pre-select into all hub sets?
The authors run experiments on historic LN snapshots and conclude that `K` should be around 100.

I must note here that I had doubts about the validity of the dataset the authors use.
The paper says that

> although the network size almost doubles from March 2019 to January 2021, the number of nodes in the largest SCC remains pretty consistent across all snapshots (≈ 2500 nodes)

This seemed to contradict other sources (like [Bitcoin Visuals](https://bitcoinvisuals.com/lightning)) that report a consistent growth in the number of nodes.
I think there is no contradiction here after all: single-directional leaf edges (corresponding to end users' nodes that can only send but not receive payments) are not part of the main _strongly_ connected component.
On the other hand, this shouldn't be surprising that optimizing hub labeling on (nearly) the same sub-graph of 2500 nodes yields (nearly) the same optimal parameter of around `100`.

In summary: LightPIR is a route discovery protocol for payment channel networks that combines private information retrieval and hub labeling.
It builds on top of prior work on path discovery for road networks and achieves higher efficiency by exploiting LN's centralized topology.
Simulations based on historical data indicate how to best parameterize LightPIR - namely, set 100 most well-connected nodes as hubs by default.



# Implementation prospects

In this section, I'll share my thoughts on the potential of LightPIR to be implemented in the Lightning network.
The ideas may be divided into two section.
First, we consider the fundamental assumptions involved in the proposed protocols.
If they are not suitable for the LN, no implementation can fix this.
Second, we turn to implementation challenges that arise.
Assuming LightPIR is a good idea for the LN _in principle_, how should it be adapted for a more realistic network model?

## Non-collusion

First of all, PIR protocols are based on the assumption that servers don't collude.
The first paper on the subject ([Chor et al., 1995](https://madhu.seas.harvard.edu/papers/1995/pir-journ.pdf)) writes:

> We assume that the servers do not collude in trying to violate the user’s privacy. <...> A detected violation of the privacy guarantees will result in severe damage to the server. It is as if a bank were caught in fraud. <...> In the rare case where the user values its potential loss as more substantial than the server’s risk, the user should not use a PIR scheme in which privacy depends on a noncollusion assumption.

The non-collusion assumption is justified with external reputation.
From the first glance, this is inapplicable in a permissionless network.
If we look deeper, however, Lightning nodes already have a somewhat persistent identity and reputation.
This is especially relevant for large nodes (so called LSPs -- Lightning Service Providers).
If the servers running the protocol belong to different entities, each putting its reputation on the line, the scheme _might_ work in practice.
The key question then would be -- how to ensure that collusion is detected?

The aforementioned paper further notes:

> The single-server computational PIR scheme of [Kushilevitz and Ostrovsky (1997)](https://web.cs.ucla.edu/~rafail/PUBLIC/34.pdf) addresses this concern.

Should we be looking into _computational_ PIR (CPIR) schemes instead of information-theoretical PIR (IT-PIR)?
What are our options?

## A single source of network graph data

The model as presented in the paper assumes there is a single source of truth regarding network topology.
In particular, a dedicated entity (the _content provider_) compiles the graph and then sends its copies to servers.
In contrast, there is no canonical network view in Lightning.
Each node composes its own network graph based on gossip messages, and different nodes may end up with different graphs.
This does not generally cause issues as everyone is very likely to be aware of the largest and best-connected nodes.

There might be two ways to reconcile the difference between theory and practice.
First, one could amend the theoretical model such that it allowed for some moderate difference between "database" copies at different servers.
Then, servers could independently compile the network graph based on gossip and still correctly reply to clients' PIR-based queries.
Second, we may see an optional LN protocol extension that does use a dedicated centralized data source.
For instance, a well-known LSP (think 1ML or LNBIG) would from time to time compile and publish a network snapshot.
Other (potentially smaller) LSPs, such as wallet providers, would download the snapshot and join the additional PIR-based network.
Clients would query a subset of wallet providers and retrieve routes privately.

## A single route quality metric

The model assumes that all clients use one common metric to evaluate route quality.
In the simplest case (ignoring fees), the model just provides _shortest_ routes.
If we assign edge costs proportional to fees, we'd be talking about _cheapest_ routes.

In the real network, clients may have different route quality metrics.
Total fees may be one component of such metrics, but it is not the only one.
Clients may also optimize for:
- route length: the longer the routes, the higher the chance of payment failure or on-path privacy attacks;
- success probability: the expected number of attempts before a payment succeeds is related to but not directly proportional to route length;
- avoiding specific nodes / regions: clients may want to route their payments around specific nodes, nodes controlled by a certain entity, nodes located in a certain region (as defined by their advertised IP address), and so on.

Again, we may address this gap between theory and practice by either changing the theory (allowing for custom route quality metrics) or changing the practice (use the protocol as is for clients that choose to prioritize low fees).


### The model doesn't account for amounts and fees

The graph model as presented in the paper is quite simplified.
First, it doesn't account for payment amounts and channel capacities, which I think is crucial for any real-world implementation.
Second, I haven't fully understood whether the model accounts for fees (that is, whether it computes the _shortest_ or the _cheapest_ routes).
Section 2 talks about a directed graph with _weighted_ edges.
Section 4.2.2 says that the hub labeling algorithm

> requires that the path weights are unique integers, but this is easily achieved with insignificant perturbations of edge weights (in our case we initially set the weights to be the channel base fees and then perturbed them).

However, as per Section 7 (Future Work):

> we do not yet take into account fees, our current work can be seen as optimised for sending a fixed amount of Bitcoin

It's not fully clear to me whether fees are considered or not.
In any case, even if the _base_ fees are considered, LN senders additionally pay fees _proportional_ to the amount.
Therefore, without accounting for the amount, we cannot build an accurate fee model either.


# Conclusion

LightPIR is a good example how protocols from non-blockchain research may be useful in blockchain context.
In the LN, economic incentives lead nodes to outsource route discovery, and it would be nice to do so in a privacy preserving way.
Still, more work is required to turn LightPIR into an implementation-ready protocol.

More practice-oriented approaches like (trampoline, rendez-vous) may use these ideas already.