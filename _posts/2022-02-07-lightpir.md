---
layout: post
title: LightPIR. Privacy-Preserving Route Discovery for Lightning (paper summary)
published: false
---

<!-- CHANGE PUBLISHED TO FALSE TO PUSH AS DRAFT -->
<!-- CHANGE DATE BEFORE PUBLICATION -->

In this post, I summarize the paper "LightPIR".
The paper outlines a new approach to route discovery in the LN.
The method combines private information retrieval with optimized hub labeling.


# Lightning routing problem

The Lightning network (LN) is source routed.
For Alice to send money to Bob, she must first choose the entire route to Bob.
To do so, Alice must store the entire network snapshot.
The same is true for any sender (the receiver doesn't have to store the graph).

One of the design constraints for the LN is that it should remain useful on small devices even as the network grows.
If we assume the LN grows by orders of magnitude, ordinary nodes (for example, those on smartphones) won't be able to keep the whole graph.
Moreover, route discovery on large graphs may also be costly.

A natural way of solving this problem is to allocate some _specialized_ nodes and outsource route discovery to them.
The key questions then are:

1. how to preserve users' privacy;
1. how to make route discovery efficient.


# PIR routing in a nutshell

The paper suggests a combination of _private information retrieval_ (PIR) and _hub labeling_ (HL) for efficient privacy-preserving routing.
The protocol has three types of roles: a content provider, servers, and clients.
In broad strokes:

1. the content provider compiles a network snapshot and sends its copies to the servers;
1. each server computes _all pairs shortest paths_ (APSP) for each pair of nodes;
1. clients query servers for routes they are interested in.

From the first glance, this idea looks terrible: servers would know which routes clients are interested in, ruining their privacy.
In what follows, I explain how the authors amend this "bad" protocol to make it privacy preserving.


# Private information retrieval

Consider a simple client-server architecture.
The server stores a database, and the client queries one row from that database.
Is it possible for a client to query a server and get a response _without the server knowing_ what the client has asked for?

This sounds absurd.
How can the server look up a row in the database without knowing which row it should look up?
Indeed, there exists an impossibility result that proves that one can only solve this challenge by transferring the whole database to the client and have the client to the lookup locally.

As it often happens when faced with an impossibility result, why not _bend_ the rules a little bit?
Instead of the problem we know is unsolvable, can we take on more assumptions and solve another problem, which is "close enough" in practcal terms?
This is exactly what private information retrieval is about.

Let's split the database among multiple servers.
Moreover, let's assume an additional security assumptions: the servers don't collude.
Now querying data privately becomes possible!

For simplicity, consider two servers with identical database copies.
Let's assume that the database holds boolean values.
Imagine the client wants to get the `i`-th element of the database.
This is how the simplest PIR protocol would work:

1. the client generates a random string `r` and another string `r'` that only differs from `r` in the `i`-th position;
1. the client sends `r` to the first server;
1. the first server responds with `d XOR r`, where `d` is the whole database;
1. the client sends `r'` to the second server;
1. the second server responds with `d XOR r`;
1. the clients computes locally `d XOR r XOR d XOR r'` with equals `d[i]`.

This simple algorithm is very ineffective.
Each of the two servers must send the entire database to the client.
On top of this, both the servers and the client must perform `O(n)` XOR operations, where `n` is the number of elements in the database.

Advanced PIR protocols make the process much more efficient.
Intuitively, the idea is to re-arrange the data into `N` dimensions, and use `N` servers.
Querying each server would yield a XOR of _some_ database elements.
The indices of such "chunks" are chosen so that when XOR'ed together, only the needed element remains.

(see this introductory video for details)

An alternative way of thinking about optimized PIR is that instead of doing `n` XOR's client-side _and_ server-side, we split the work between the client and the server.
Each server does some "pre-XOR'ing" in a clever way so that the client can XOR the results and obtain the element it is interested in.


# Hub labeling

Let's now talk efficiency.
Even if clients outsource route discovery to servers, servers still must do the work.
The server must either run a route search algorithm each time it is queried, or pre-compute shortest paths for all node pairs and look it up upon a query.
For very large graphs, both operations may become computationally prohibitive, either in terms of storage or computational costs.

Yet, as we know from the experience of using online maps, route discovery works well on very large graphs.
One can pick two points on the opposite coasts of a continent and see the route between them in a few seconds.
How is this possible?

Turns out, graph algorithms have been optimized a lot for road networks.
For practical applications, we don't need efficient algorithms on _any_ graphs -- we are only interested in graphs that have some practical relevance, for example, road graphs.
Turns out, road graphs have a special structure that allows for massive optimizations.
In particular, road networks are very "centralized": any sufficiently long route must go through one of a handful of intersections.
Intuitively speaking, driving between cities in the majority of cases happens in these steps: enter a highway, drive along, exit the highway.
Highways comprise the minority of all roads but are responsible for the vast majority of routes (essentially, all routes with endpoints in different cities).

Accounting for this graph structure, route discovery algorithms for road graphs rely on _hub labeling_.
Each node is populated with links to hubs and the _shortest paths_ to each of the hubs.
Hubs are chosen such that (cover property).
Therefore, calculating a route between Alice and Bob happens like this:
1. find which hubs belong both to Alice's and Bob's hub sets;
1. the route is: Alice - common hub - Bob.

This approach can be thought of as an improvement upon a simplistic solution that stores all shortest paths for all node pairs (APSP).
Instead, we now store shortest path only to a handful of "important" nodes (hubs), yet it's sufficient to calculate the shortest route between every pair of nodes, if the hub sets are chosen in a clever way.


# LightPIR: putting this all together

So what exactly does the LightPIR paper propose?
It proposes combining hub labeling with shortest paths pre-calculation.
Additionally (and here lies the novelty), the paper argues that for the LN specifically the algorithms from road networks may be improved _even more_.

The improved hub labeling for the LN works as follows.
It is based roughly on the idea that nodes with high degree are likely important for most routes.
Therefore it makes sense to include them in all hub sets from the get-go.
An optimized hub labeling algorithm would go like this:
1. select `K` nodes with the highest degree, put them in the hub set for all nodes (IS TI TRUE?)
1. exclude those hubs from the graph
1. find the "remaining" hubs based on the "truncated" graph.

Intuitively, instead of "discovering" again and again that, say, the Eclair node (the most connected node in the open network) is a hub for Alice, and for Bob, and for Charlie (what a surprise!), we simply assign it as a hub for all of them.
More "node-specific" hubs are then discovered on a truncated graph, which further simplifies calculations.

It's worth mentioning that the algorithm for calculating the _exact_ hub set is NP-full.
We don't want to be doing it for any non-trivial graph.
Hence, everything is about heuristics: every hub labeling algorithm will find _some_ hub set that would work (i.e., would cover all paths) but would likely be sub-optimal (there exists a smaller hub set but it's very hard to discover).

How many top-nodes shall we pre-select into the hub set?
The authors run a series of experiments on a set of historic LN snapshots and conclude that `K` should be around 100.

In summary: LightPIR is a protocol for route discovery for the LN.
LN "full nodes" (servers) pre-compute shortest paths to hubs.
LN "light nodes" (clients) query multiple servers via a PIR protocol so that the servers don't know what routes they ask for.
The new optimized hub labeling algorithm that exploits the centralized topology of the LN makes the whole process more efficient than prior approaches.
Measurements on prior LN snapshots indicate how to best parameterize hub labeling - namely, assign 100 most well-connected nodes to all hub sets bu default.




# My analysis

In this section, I'll share my opinion and some questions that I feel would need to be resolved to make LightPIR a working protocol implemented in Lightning.
I like the overall approach, although there are a few points that remained unclear to me.


## The graph model is too simplified

The graph model doesn't account for amounts and for fees.


## A single utility function (cost)

The model inherently assumes that all clients have the same utility function on routes.
This is often referred to as "shortest" routes.
If we account for fees, we may re-formulate it as "cheapest" routes.
However, even then, let's acknowledge that not all clients necessarily want the cheapest routes!
Some may want avoid going through specific hubs, and so on.
Can the model be extended to allow clients to specify a weighted cost function of multiple components (route length, fee, probability of success, probability of certain attacks as estimated with ... ).


## Non-collusion assumption

The fundamental assumption behind PIR is that nodes don't collude.
Is this a reasonable assumption in a decentralized network?
Could there at least be a way for a user to _detect_ collusion if it happens?


## A single source of graph data

The model assumes there is one "true" graph supplied by the "content provider".
In the real LN, each node composes its own graph model based on gossip.
There is no one authoritative list of LN nodes.

The LightPIR model may still be useful, for example, in this scenario.
A large node (think 1ML, Eclair or LNBig) compiles a canonical graph snapshot once in a while and published it.
Independent nodes (think wallet providers) download it and provide an API for clients.
A client queries multiple randomly chosen nodes using PIR to get the route.


## Strange data (2500 nodes remain)

I have a suspicion that the dataset the authors used is corrupt in some way.
They say that the largest strongly connected component remained static at 2500 nodes throughout 2020-2021.
Other sources disagree (SOURCES).


# Conclusion

LightPIR is a good example how protocols from non-blockchain research may be useful in blockchain context.
In the LN, economic incentives lead nodes to outsource route discovery, and it would be nice to do so in a privacy preserving way.
Still, more work is required to turn LightPIR into an implementation-ready protocol.

More practice-oriented approaches like (trampoline, rendez-vous) may use these ideas already.